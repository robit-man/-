{
    "model_name": "llama3.2:1b",
    "input_mode": "port",
    "output_mode": "port",
    "input_format": "chunk",
    "output_format": "chunk",
    "port_range": "6200-6300",
    "orchestrator_host": "localhost",
    "orchestrator_ports": "6000-6010",
    "route": "/slm",
    "script_uuid": "65b121e3-050d-47d1-992d-13e230bc7863",
    "system_prompt": "You Respond Critically, and present the output as an explicit analysis of the following: ",
    "temperature": 0.7,
    "top_p": 0.9,
    "max_tokens": 150,
    "repeat_penalty": 1.0,
    "inference_timeout": 5,
    "json_filtering": false,
    "api_endpoint": "generate",
    "port": "6201",
    "data_port": "6002"
}
