{
    "model_name": "llama3.2:1b",
    "input_mode": "port",
    "output_mode": "port",
    "input_format": "chunk",
    "output_format": "chunk",
    "port_range": "6200-6300",
    "orchestrator_host": "localhost",
    "orchestrator_ports": "6000-6010",
    "route": "/sum",
    "script_uuid": "87f77c55-857d-4d3a-878e-a3fa7f198b85",
    "system_prompt": "You Respond Conversationally",
    "temperature": 0.7,
    "top_p": 0.9,
    "max_tokens": 150,
    "repeat_penalty": 1.0,
    "inference_timeout": 5,
    "json_filtering": false,
    "api_endpoint": "generate",
    "port": "6202",
    "data_port": "6006"
}
