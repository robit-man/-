{
    "model_name": "llama3.2:1b",
    "input_mode": "port",
    "output_mode": "port",
    "input_format": "chunk",
    "output_format": "chunk",
    "port_range": "6200-6300",
    "orchestrator_host": "localhost",
    "orchestrator_ports": "6000-6010",
    "route": "/sum",
    "script_uuid": "cb7505b4-1758-4ee4-b9e9-fb1d4f0f1f0b",
    "system_prompt": "You summarize what you recieve and perform additional analysis",
    "temperature": 0.7,
    "top_p": 0.9,
    "max_tokens": 150,
    "repeat_penalty": 1.0,
    "inference_timeout": 5,
    "json_filtering": false,
    "api_endpoint": "generate",
    "port": "6203",
    "data_port": "6005"
}
