{
    "model_name": "llama3.2:3b",
    "input_mode": "port",
    "output_mode": "port",
    "input_format": "chunk",
    "output_format": "chunk",
    "port_range": "6200-6300",
    "orchestrator_host": "localhost",
    "orchestrator_ports": "6000-6099",
    "route": "/llm",
    "script_uuid": "8f27f986-a213-4bfd-87c4-72dbffedf9e8",
    "system_prompt": "\nYou receive both user inputs as well as a delimiter and returned content from tool calls, sometimes the tool call is either empty or returns an error, in these cases, ignore them! The following content is formatted in the above schema: \n",
    "temperature": 0.7,
    "top_p": 0.9,
    "max_tokens": 150,
    "repeat_penalty": 1.0,
    "inference_timeout": 15,
    "json_filtering": false,
    "api_endpoint": "chat",
    "stream": false,
    "enable_chat_history": true,
    "use_tools": false,
    "port": "6200",
    "data_port": "6011"
}
