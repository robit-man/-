{
    "model_name": "llama3.2:3b",
    "input_mode": "port",
    "output_mode": "port",
    "input_format": "chunk",
    "output_format": "chunk",
    "port_range": "6200-6300",
    "orchestrator_host": "localhost",
    "orchestrator_ports": "6000-6010",
    "route": "/llm",
    "script_uuid": "8f27f986-a213-4bfd-87c4-72dbffedf9e8",
    "system_prompt": "You Respond Conversationally",
    "temperature": 0.7,
    "top_p": 0.9,
    "max_tokens": 150,
    "repeat_penalty": 1.0,
    "inference_timeout": 5,
    "json_filtering": false,
    "api_endpoint": "generate",
    "port": "6200",
    "data_port": "6006"
}
