#!/usr/bin/env python3

import os
import sys
import subprocess
import curses
import curses.textpad  # Ensure this import is present
import json
import requests
import threading
import textwrap
from pathlib import Path
from queue import Queue, Empty
import logging
import time
import re
from datetime import datetime, timedelta
import zipfile
import shutil

# ======================= Configuration Constants =======================
VENV_DIR = "voice_venv"
API_URL = "http://127.0.0.1:11434/api/chat"  # Using '127.0.0.1' for offline use
MODEL_NAME = "llama3.2:1b"  # Replace with your model name
CONFIG_FILE = "config.json"
CHAT_HISTORY_FILE = "chat_history.json"  # Path to chat history file
VOSK_MODEL_PATH = "models/vosk-model-small-en-us-0.15"  # Path to Vosk model
VOSK_MODEL_ZIP_URL = "https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip"  # URL to download the Vosk model
DEFAULT_CONFIG = {
    "system_prompt": "You are a helpful assistant.",
    "ollama_chat_history": True,
    "history_limit": 20,            # New configuration for chat history limit
    "temperature": 0.7,
    "tts_enabled": True,            # Enable TTS by default
    "tts_voice": "slt"               # Default flite voice
}

# ======================= Logging Configuration ==========================
logging.basicConfig(
    filename='app.log',
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# ======================= Suppress ALSA and JACK Warnings ==================
def redirect_stderr():
    """Redirects the OS-level stderr to suppress ALSA and JACK errors."""
    sys.stderr.flush()
    devnull = open(os.devnull, 'w')
    os.dup2(devnull.fileno(), sys.stderr.fileno())

redirect_stderr()

# ======================= Subprocess stderr suppression ====================
SUBPROCESS_STDERR = subprocess.DEVNULL

# ======================= Configuration Management Functions ============
def load_config():
    """Load configuration from CONFIG_FILE or create it with DEFAULT_CONFIG."""
    if not os.path.exists(CONFIG_FILE):
        save_config(DEFAULT_CONFIG)
        logging.info("Config file not found. Created default config.")
        return DEFAULT_CONFIG.copy()
    else:
        try:
            with open(CONFIG_FILE, 'r') as f:
                config = json.load(f)
            # Ensure all default keys exist
            updated = False
            for key, value in DEFAULT_CONFIG.items():
                if key not in config:
                    config[key] = value
                    updated = True
                elif key == "history_limit":
                    try:
                        config[key] = int(config[key])
                    except ValueError:
                        config[key] = DEFAULT_CONFIG[key]
                        updated = True
            if updated:
                save_config(config)
                logging.info("Updated config with missing or invalid default keys.")
            return config
        except (json.JSONDecodeError, IOError) as e:
            logging.error(f"Error loading config: {e}. Recreating default config.")
            save_config(DEFAULT_CONFIG)
            return DEFAULT_CONFIG.copy()

def save_config(config):
    """Save configuration to CONFIG_FILE."""
    try:
        with open(CONFIG_FILE, 'w') as f:
            json.dump(config, f, indent=4)
        logging.info("Configuration saved successfully.")
    except IOError as e:
        logging.error(f"Failed to save configuration: {e}")
        print(f"Failed to save configuration: {e}")

# ======================= Virtual Environment Setup ======================
def is_venv():
    """Check if the script is running inside a virtual environment."""
    return (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix) or \
           (hasattr(sys, 'real_prefix') and sys.real_prefix != sys.prefix)

def create_venv():
    if not os.path.exists(VENV_DIR):
        logging.info("Creating virtual environment.")
        result = subprocess.run([sys.executable, "-m", "venv", VENV_DIR], stderr=SUBPROCESS_STDERR)
        if result.returncode != 0:
            logging.error("Failed to create virtual environment.")
            sys.exit("Error: Failed to create virtual environment.")
        logging.info("Virtual environment created.")
        print("Virtual environment created.")
    else:
        logging.info("Virtual environment already exists.")
        print("Virtual environment already exists.")

def install_dependencies():
    logging.info("Installing dependencies.")
    # Determine the pip executable path based on OS
    if os.name == 'nt':
        pip_executable = os.path.join(VENV_DIR, "Scripts", "pip.exe")
    else:
        pip_executable = os.path.join(VENV_DIR, "bin", "pip")
    
    # Define required package versions to prevent multiple version attempts
    required_packages = [
        "SpeechRecognition",
        "pyaudio",
        "vosk",
        "requests",
        "numpy",
        "transformers==4.33.0",  # Specific version to prevent multiple downloads
        "umap-learn==0.5.6"      # Specific version to prevent multiple downloads
    ]
    
    try:
        # Upgrade pip
        subprocess.check_call([pip_executable, "install", "--upgrade", "pip"], stderr=SUBPROCESS_STDERR)
        # Install required packages with specified versions
        subprocess.check_call([pip_executable, "install"] + required_packages, stderr=SUBPROCESS_STDERR)
        logging.info("Dependencies installed successfully.")
        print("Dependencies installed.")
    except subprocess.CalledProcessError as e:
        logging.error(f"Dependency installation failed: {e}")
        sys.exit("Error: Failed to install dependencies. Check app.log for details.")

def activate_venv():
    """Activate virtual environment by updating sys.path."""
    if os.name == 'nt':
        venv_site_packages = Path(VENV_DIR) / "Lib" / "site-packages"
    else:
        venv_site_packages = Path(VENV_DIR) / "lib" / f"python{sys.version_info.major}.{sys.version_info.minor}" / "site-packages"
    sys.path.insert(0, str(venv_site_packages))
    logging.info("Virtual environment activated.")
    print("Virtual environment activated.")

# ======================= Vosk Model Downloader ============================
def download_vosk_model():
    """Download and extract the Vosk model if not already present."""
    if os.path.exists(VOSK_MODEL_PATH):
        logging.info(f"Vosk model already exists at {VOSK_MODEL_PATH}.")
        return
    os.makedirs(os.path.dirname(VOSK_MODEL_PATH), exist_ok=True)
    model_zip_path = VOSK_MODEL_PATH + ".zip"
    try:
        logging.info(f"Downloading Vosk model from {VOSK_MODEL_ZIP_URL}...")
        print("Downloading Vosk model. This may take a few minutes...")
        response = requests.get(VOSK_MODEL_ZIP_URL, stream=True)
        response.raise_for_status()
        total_size = int(response.headers.get('content-length', 0))
        with open(model_zip_path, 'wb') as f:
            downloaded = 0
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
                    done = int(50 * downloaded / total_size)
                    sys.stdout.write('\r[{}{}]'.format('â–ˆ' * done, '.' * (50-done)))
                    sys.stdout.flush()
        print("\nDownload completed.")
        logging.info("Vosk model downloaded successfully.")
        
        # Extract the zip file
        logging.info(f"Extracting Vosk model to {VOSK_MODEL_PATH}...")
        print("Extracting Vosk model...")
        with zipfile.ZipFile(model_zip_path, 'r') as zip_ref:
            zip_ref.extractall(os.path.dirname(VOSK_MODEL_PATH))
        logging.info("Vosk model extracted successfully.")
        print("Vosk model extracted successfully.")
        
        # Remove the zip file
        os.remove(model_zip_path)
    except requests.RequestException as e:
        logging.error(f"Failed to download Vosk model: {e}")
        print(f"Error: Failed to download Vosk model: {e}")
        sys.exit("Error: Failed to download Vosk model.")
    except zipfile.BadZipFile as e:
        logging.error(f"Failed to extract Vosk model: {e}")
        print(f"Error: Failed to extract Vosk model: {e}")
        sys.exit("Error: Failed to extract Vosk model.")

# ======================= Text-to-Speech Handler Using flite ==============
class TTSHandler:
    def __init__(self, voice='slt'):
        self.voice = voice  # Default voice
        self.queue = Queue()
        self.thread = threading.Thread(target=self.run)
        self.stop_event = threading.Event()
        self.thread.start()
        logging.info("TTSHandler initialized successfully.")
    
    def run(self):
        while not self.stop_event.is_set():
            try:
                sentence = self.queue.get(timeout=0.1)
                if sentence:
                    logging.debug(f"TTSHandler is speaking: {sentence}")
                    # Invoke flite with the selected voice
                    subprocess.run(['flite', '-voice', self.voice, '-t', sentence], check=True, stderr=subprocess.PIPE)
                    logging.debug(f"TTSHandler finished speaking: {sentence}")
            except Empty:
                continue
            except subprocess.CalledProcessError as e:
                error_output = e.stderr.decode().strip()
                logging.error(f"flite failed to speak '{sentence}': {error_output}")
            except Exception as e:
                logging.error(f"Unexpected error in TTSHandler: {e}")
    
    def speak(self, sentence):
        logging.debug(f"Enqueuing sentence for TTS: {sentence}")
        self.queue.put(sentence)
    
    def stop(self):
        logging.info("Stopping TTSHandler...")
        self.stop_event.set()
        self.thread.join()
        logging.info("TTSHandler stopped.")

# ======================= Chat History Management ==========================
def load_chat_history(config):
    """Load chat history from CHAT_HISTORY_FILE if enabled."""
    if config.get("ollama_chat_history", False):
        if os.path.exists(CHAT_HISTORY_FILE):
            try:
                with open(CHAT_HISTORY_FILE, 'r') as f:
                    chat_history = json.load(f)
                logging.info("Chat history loaded successfully.")
                # Ensure system prompt is the first message
                if not chat_history or chat_history[0].get("role") != "system":
                    chat_history.insert(0, {"role": "system", "content": config.get("system_prompt", "You are a helpful assistant.")})
                return chat_history
            except (json.JSONDecodeError, IOError) as e:
                logging.error(f"Error loading chat history: {e}. Starting with empty history.")
                return [{"role": "system", "content": config.get("system_prompt", "You are a helpful assistant.")}]
        else:
            logging.info("Chat history file not found. Starting with system prompt.")
            return [{"role": "system", "content": config.get("system_prompt", "You are a helpful assistant.")}]
    else:
        return []

def save_chat_history(chat_history):
    """Save chat history to CHAT_HISTORY_FILE."""
    try:
        with open(CHAT_HISTORY_FILE, 'w') as f:
            json.dump(chat_history, f, indent=4)
        logging.info("Chat history saved successfully.")
    except IOError as e:
        logging.error(f"Failed to save chat history: {e}")

def append_to_chat_history(chat_history, role, content, config):
    """Append a new message to chat history and enforce history limit."""
    if not config.get("ollama_chat_history", False):
        logging.info("Chat history is disabled. Skipping append.")
        return chat_history
    chat_history.append({"role": role, "content": content})
    # Enforce history limit
    history_limit = config.get("history_limit", 20)
    if len(chat_history) > history_limit:
        chat_history = chat_history[-history_limit:]
    save_chat_history(chat_history)
    return chat_history

def get_recent_chat_history(chat_history, history_limit):
    """Return the last `history_limit` messages from chat history."""
    if len(chat_history) > history_limit:
        return chat_history[-history_limit:]
    return chat_history

# ======================= Speech Recognition Thread with Vosk ============
def speech_recognition_thread(text_queue, stop_event):
    from vosk import Model, KaldiRecognizer, SetLogLevel
    import sys
    import wave

    SetLogLevel(-1)  # Suppress Vosk logs

    if not os.path.exists(VOSK_MODEL_PATH):
        error_msg = f"Vosk model not found at {VOSK_MODEL_PATH}. Please download and place it accordingly."
        text_queue.put(error_msg)
        logging.error(error_msg)
        return

    try:
        model = Model(VOSK_MODEL_PATH)
        recognizer = KaldiRecognizer(model, 16000)
    except Exception as e:
        error_msg = f"Failed to initialize Vosk model: {e}"
        text_queue.put(error_msg)
        logging.error(error_msg)
        return

    import pyaudio

    p = pyaudio.PyAudio()

    try:
        stream = p.open(format=pyaudio.paInt16,
                        channels=1,
                        rate=16000,
                        input=True,
                        frames_per_buffer=4000)
        stream.start_stream()
    except Exception as e:
        error_msg = f"Microphone error: {e}"
        text_queue.put(error_msg)
        logging.error(error_msg)
        return

    while not stop_event.is_set():
        try:
            data = stream.read(4000, exception_on_overflow=False)
            if recognizer.AcceptWaveform(data):
                result = recognizer.Result()
                result_json = json.loads(result)
                text = result_json.get("text", "")
                if text:
                    text_queue.put(text)
                    logging.info(f"Recognized speech: {text}")
            else:
                partial = recognizer.PartialResult()
                # Optionally handle partial results
        except Exception as e:
            error_msg = f"Speech Recognition error: {e}"
            text_queue.put(error_msg)
            logging.error(error_msg)
            break

    stream.stop_stream()
    stream.close()
    p.terminate()

# ======================= Ollama API Streaming ============================
def send_to_ollama_api_stream(text, response_queue, stop_event, config, chat_history):
    headers = {"Content-Type": "application/json"}
    messages = []

    if config["ollama_chat_history"]:
        messages = get_recent_chat_history(chat_history, config.get("history_limit", 20)).copy()
        # Append the new user message
        messages.append({"role": "user", "content": text})
    else:
        messages = [
            {"role": "system", "content": config["system_prompt"]},
            {"role": "user", "content": text}
        ]

    data = {
        "model": MODEL_NAME,
        "messages": messages,
        "options": {
            "temperature": config["temperature"]
        },
        "stream": True  # Enable streaming
    }

    logging.debug(f"Sending messages to Ollama API: {json.dumps(messages, indent=2)}")
    
    try:
        with requests.post(API_URL, headers=headers, json=data, stream=True, timeout=60) as response:
            response.raise_for_status()
            for line in response.iter_lines():
                if stop_event.is_set():
                    break
                if line:
                    try:
                        decoded_line = line.decode('utf-8')
                        json_obj = json.loads(decoded_line)
                        if 'message' in json_obj and 'content' in json_obj['message']:
                            content = json_obj['message']['content']
                            response_queue.put(content)
                            logging.debug(f"Received content: {content}")
                    except json.JSONDecodeError:
                        continue  # Ignore malformed JSON lines
    except requests.RequestException as e:
        error_msg = f"Failed to send to Ollama: {e}"
        response_queue.put(error_msg)
        logging.error(error_msg)
    finally:
        # Signal that the API streaming is done
        response_queue.put(None)

# ======================= Curses Menu System ==============================
class Menu:
    def __init__(self, stdscr, config, tts_handler, chat_history):
        self.stdscr = stdscr
        self.config = config
        self.tts_handler = tts_handler
        self.chat_history = chat_history
        self.menu_items = [
            "Set System Prompt",
            "Toggle Ollama Chat History",
            "Set Temperature",
            "Toggle Text-to-Speech",
            "Set TTS Voice",
            "Clear Chat History",      # New menu item
            "View Chat History",       # Optional: View current chat history
            "Back to Main"
        ]
        self.current_selection = 0

    def display_menu(self):
        self.stdscr.clear()
        h, w = self.stdscr.getmaxyx()
        title = "Configuration Menu (Use Arrow Keys & Enter)"
        self.stdscr.addstr(1, w//2 - len(title)//2, title, curses.A_BOLD | curses.A_UNDERLINE)
        for idx, item in enumerate(self.menu_items):
            x = w//2 - 20
            y = 3 + idx
            if idx == self.current_selection:
                self.stdscr.attron(curses.color_pair(1))
                self.stdscr.addstr(y, x, f"> {item}")
                self.stdscr.attroff(curses.color_pair(1))
            else:
                self.stdscr.addstr(y, x, f"  {item}")
        self.stdscr.refresh()

    def navigate(self, key):
        if key == curses.KEY_UP and self.current_selection > 0:
            self.current_selection -= 1
        elif key == curses.KEY_DOWN and self.current_selection < len(self.menu_items) - 1:
            self.current_selection += 1

    def run(self):
        curses.init_pair(1, curses.COLOR_BLACK, curses.COLOR_WHITE)
        while True:
            self.display_menu()
            key = self.stdscr.getch()
            if key in [curses.KEY_UP, curses.KEY_DOWN]:
                self.navigate(key)
            elif key in [curses.KEY_ENTER, 10, 13]:
                selected_item = self.menu_items[self.current_selection]
                if selected_item == "Set System Prompt":
                    self.set_system_prompt()
                elif selected_item == "Toggle Ollama Chat History":
                    self.toggle_chat_history()
                elif selected_item == "Set Temperature":
                    self.set_temperature()
                elif selected_item == "Toggle Text-to-Speech":
                    self.toggle_tts()
                elif selected_item == "Set TTS Voice":
                    self.set_tts_voice()
                elif selected_item == "Clear Chat History":
                    self.clear_chat_history()
                elif selected_item == "View Chat History":
                    self.view_chat_history()
                elif selected_item == "Back to Main":
                    break

    def set_system_prompt(self):
        prompt = self.get_input("Enter new system prompt:", self.config["system_prompt"])
        if prompt is not None:
            self.config["system_prompt"] = prompt
            save_config(self.config)
            self.show_message("System prompt updated successfully.")
            if self.tts_handler and self.config.get("tts_enabled", False):
                self.tts_handler.speak("System prompt updated successfully.")

    def toggle_chat_history(self):
        self.config["ollama_chat_history"] = not self.config["ollama_chat_history"]
        save_config(self.config)
        status = "enabled" if self.config["ollama_chat_history"] else "disabled"
        self.show_message(f"Ollama Chat History {status}.")
        if self.tts_handler and self.config.get("tts_enabled", False):
            self.tts_handler.speak(f"Ollama Chat History {status}.")

    def set_temperature(self):
        while True:
            temp = self.get_input("Set temperature (0.0 to 1.0):", str(self.config["temperature"]))
            if temp is None:
                break  # User cancelled
            try:
                temp_val = float(temp)
                if 0.0 <= temp_val <= 1.0:
                    self.config["temperature"] = temp_val
                    save_config(self.config)
                    self.show_message("Temperature updated successfully.")
                    if self.tts_handler and self.config.get("tts_enabled", False):
                        self.tts_handler.speak("Temperature updated successfully.")
                    break
                else:
                    self.show_message("Please enter a value between 0.0 and 1.0.")
            except ValueError:
                self.show_message("Invalid input. Please enter a numerical value.")

    def toggle_tts(self):
        self.config["tts_enabled"] = not self.config["tts_enabled"]
        save_config(self.config)
        status = "enabled" if self.config["tts_enabled"] else "disabled"
        self.show_message(f"Text-to-Speech {status}.")
        if status == "enabled":
            if self.tts_handler is None:
                try:
                    self.tts_handler = TTSHandler(voice=self.config.get("tts_voice", "slt"))
                    self.tts_handler.speak("Text-to-speech enabled.")
                except Exception as e:
                    logging.error(f"Failed to initialize TTSHandler: {e}")
                    self.show_message(f"Failed to initialize TTS: {e}")
        else:
            if self.tts_handler:
                self.tts_handler.stop()
                self.tts_handler = None

    def set_tts_voice(self):
        available_voices = self.get_available_flite_voices()
        if not available_voices:
            self.show_message("No available flite voices found.")
            return
        voice = self.get_input(f"Enter TTS Voice ({', '.join(available_voices)}):", self.config.get("tts_voice", 'slt'))
        if voice in available_voices:
            self.config["tts_voice"] = voice
            save_config(self.config)
            if self.tts_handler:
                self.tts_handler.voice = voice  # Update the voice in TTSHandler
            self.show_message(f"TTS Voice set to {voice}.")
            if self.tts_handler and self.config.get("tts_enabled", False):
                self.tts_handler.speak(f"TTS voice set to {voice}.")
        else:
            self.show_message("Invalid voice selected.")

    def clear_chat_history(self):
        if not self.config.get("ollama_chat_history", False):
            self.show_message("Chat history is disabled.")
            return
        confirm = self.get_input("Are you sure you want to clear chat history? (y/n):", "n")
        if confirm.lower() == 'y':
            try:
                with open(CHAT_HISTORY_FILE, 'w') as f:
                    json.dump([], f, indent=4)
                self.chat_history.clear()
                self.show_message("Chat history cleared successfully.")
                if self.tts_handler and self.config.get("tts_enabled", False):
                    self.tts_handler.speak("Chat history cleared successfully.")
            except IOError as e:
                logging.error(f"Failed to clear chat history: {e}")
                self.show_message(f"Failed to clear chat history: {e}")
        else:
            self.show_message("Chat history not cleared.")

    def view_chat_history(self):
        if not self.config.get("ollama_chat_history", False):
            self.show_message("Chat history is disabled.")
            return
        if not self.chat_history:
            self.show_message("No chat history available.")
            return
        # Display the last `history_limit` entries
        history_to_display = self.chat_history[-self.config.get("history_limit", 20):]
        display_text = "\n".join([f"{entry['role'].capitalize()}: {entry['content']}" for entry in history_to_display])
        self.show_message(f"Chat History:\n{display_text}")

    def get_available_flite_voices(self):
        """Retrieve available flite voices."""
        try:
            result = subprocess.run(['flite', '-lv'], capture_output=True, text=True, check=True)
            voices = [line.strip() for line in result.stdout.split('\n') if line.strip()]
            return voices
        except subprocess.CalledProcessError as e:
            logging.error(f"Failed to retrieve flite voices: {e.stderr.strip()}")
            return []
        except FileNotFoundError:
            logging.error("flite is not installed or not found in PATH.")
            return []

    def get_input(self, prompt, default=""):
        # Removed curses.echo() to prevent double echoing
        self.stdscr.clear()
        h, w = self.stdscr.getmaxyx()
        prompt_str = f"{prompt}"
        self.stdscr.addstr(h//2 - 1, w//2 - len(prompt_str)//2, prompt_str)
        self.stdscr.addstr(h//2, w//2 - 10, "> ")
        self.stdscr.refresh()
        # Create a window for input
        input_width = min(len(default) + 20, w - (w//2 - 10) - 4)
        input_win = curses.newwin(1, input_width, h//2, w//2 - 8)
        box = curses.textpad.Textbox(input_win)
        try:
            # Disable echoing for the window since Textbox handles it
            user_input = box.edit().strip()
        except curses.error:
            user_input = ""
        return user_input if user_input else default

    def show_message(self, message):
        self.stdscr.clear()
        h, w = self.stdscr.getmaxyx()
        try:
            # Split message into lines if it's too long
            lines = message.split('\n')
            for idx, line in enumerate(lines):
                if idx >= h - 4:
                    break  # Prevent writing beyond the window
                self.stdscr.addstr(h//2 - len(lines)//2 + idx, w//2 - len(line)//2, line[:w-1])
            self.stdscr.addstr(h//2 + 2, w//2 - 10, "Press any key to continue.")
            self.stdscr.refresh()
            self.stdscr.getch()
        except curses.error:
            pass  # Ignore if the string is too long for the window

# ======================= Main curses display loop with Menu Integration =========================
def main(stdscr):
    # Initialize curses settings
    curses.curs_set(0)  # Hide cursor
    stdscr.clear()
    stdscr.nodelay(True)  # Make getch() non-blocking
    stdscr.timeout(100)   # Set timeout for screen refresh rate

    # Load or create configuration
    config = load_config()

    # Load chat history
    chat_history = load_chat_history(config)

    # Set up virtual environment and dependencies
    create_venv()
    install_dependencies()
    activate_venv()

    # Download Vosk model if not present
    download_vosk_model()

    # Import modules within the activated virtual environment
    try:
        from vosk import Model, KaldiRecognizer
    except ImportError as e:
        stdscr.addstr(0, 0, f"Failed to import Vosk: {e}")
        stdscr.refresh()
        stdscr.getch()
        return

    # Initialize recognizer and microphone
    # Vosk handles microphone within the speech_recognition_thread
    # So no need to initialize here

    # Queues for inter-thread communication
    text_queue = Queue()
    response_queue = Queue()

    # Event to signal threads to stop
    stop_event = threading.Event()

    # Initialize TTS Handler if enabled
    tts_handler = None
    if config.get("tts_enabled", False):
        try:
            tts_handler = TTSHandler(voice=config.get("tts_voice", "slt"))
            # Enqueue "System started." message
            tts_handler.speak("System started.")
        except Exception as e:
            logging.error(f"Failed to initialize TTSHandler: {e}")
            display_error(stdscr, f"Failed to initialize TTS: {e}", tts_handler, config)
            return  # Exit the main loop

    # Start speech recognition thread
    speech_thread = threading.Thread(target=speech_recognition_thread, args=(text_queue, stop_event))
    speech_thread.daemon = True
    speech_thread.start()

    # Variables to handle API responses
    api_thread = None
    ollama_response = ""
    last_speech_time = None
    accumulated_text = ""

    # Initialize conversation log with system prompt
    conversation_log = [{"role": "system", "content": config.get("system_prompt", "You are a helpful assistant.")}]
    MAX_CONVERSATION_LINES = 100  # Adjust as needed

    # Define a regex pattern to detect sentence endings
    sentence_end_pattern = re.compile(r'.*[.!?]$')

    try:
        while True:
            # Check for user input
            try:
                key = stdscr.getch()
            except:
                key = -1

            if key != -1:
                if key in [ord('q'), ord('Q')]:
                    break
                elif key in [ord('m'), ord('M')]:
                    # Open Menu
                    menu = Menu(stdscr, config, tts_handler, chat_history)
                    menu.run()
                    # Reload config in case it was changed
                    config = load_config()
                    # Reload chat history in case it was cleared
                    chat_history = load_chat_history(config)
                    # Handle TTS Handler based on updated config
                    if config.get("tts_enabled", False) and not tts_handler:
                        try:
                            tts_handler = TTSHandler(voice=config.get("tts_voice", "slt"))
                            tts_handler.speak("Text-to-speech enabled.")
                        except Exception as e:
                            logging.error(f"Failed to initialize TTSHandler: {e}")
                            display_error(stdscr, f"Failed to initialize TTS: {e}", tts_handler, config)
                    elif not config.get("tts_enabled", False) and tts_handler:
                        tts_handler.stop()
                        tts_handler = None
                    continue

            # Check if any new recognized text is available
            try:
                text = text_queue.get_nowait()
                if text.startswith("Speech Recognition error:"):
                    conversation_log.append({"role": "error", "content": text})
                else:
                    if text:
                        accumulated_text += " " + text
                        last_speech_time = datetime.now()
                        conversation_log.append({"role": "user", "content": text})
                        # Append user input to chat history
                        chat_history = append_to_chat_history(chat_history, "user", text, config)
            except Empty:
                pass

            # Check if 2 seconds have passed since last speech
            if accumulated_text and last_speech_time:
                if datetime.now() - last_speech_time > timedelta(seconds=2):
                    # Send accumulated_text to Ollama API
                    if api_thread and api_thread.is_alive():
                        stop_event.set()
                        api_thread.join()
                        stop_event.clear()
                    # Append a new entry for Ollama's response
                    conversation_log.append({"role": "assistant", "content": ""})
                    assistant_entry_index = len(conversation_log) - 1
                    api_thread = threading.Thread(target=send_to_ollama_api_stream, args=(accumulated_text.strip(), response_queue, stop_event, config, chat_history))
                    api_thread.daemon = True
                    api_thread.start()
                    accumulated_text = ""
                    last_speech_time = None

            # Check if any new API response tokens are available
            try:
                while True:
                    token = response_queue.get_nowait()
                    if token is None:
                        # API response is complete
                        if ollama_response.strip():
                            complete_response = ollama_response.strip()
                            # Pass the complete response to flite
                            if config.get("tts_enabled", False) and tts_handler:
                                tts_handler.speak(complete_response)
                            # Append assistant's response to chat history
                            chat_history = append_to_chat_history(chat_history, "assistant", complete_response, config)
                            # Add separator line to conversation_log
                            conversation_log.append({"role": "separator", "content": "----- Generated"})
                            # Reset variables
                            ollama_response = ""
                        break
                    elif token.startswith("Failed to send to Ollama:"):
                        conversation_log.append({"role": "error", "content": token})
                    else:
                        ollama_response += token
                        logging.debug(f"Received token: {token}")
                        # Append token to the assistant's last message
                        if 'assistant_entry_index' in locals():
                            conversation_log[assistant_entry_index]['content'] += token
            except Empty:
                pass

            # Limit conversation_log to last MAX_CONVERSATION_LINES entries
            while len(conversation_log) > MAX_CONVERSATION_LINES:
                conversation_log.pop(0)

            # Get terminal dimensions
            height, width = stdscr.getmaxyx()

            # Clear the screen
            stdscr.erase()

            # Display conversation_log entries with wrapping
            display_lines = []
            for entry in conversation_log:
                if entry['role'] == 'system':
                    wrapped_lines = textwrap.wrap(f"System: {entry['content']}", width=width-1)
                elif entry['role'] == 'user':
                    wrapped_lines = textwrap.wrap(f"User: {entry['content']}", width=width-1)
                elif entry['role'] == 'assistant':
                    wrapped_lines = textwrap.wrap(f"Ollama: {entry['content']}", width=width-1)
                elif entry['role'] == 'error':
                    wrapped_lines = textwrap.wrap(f"Error: {entry['content']}", width=width-1)
                elif entry['role'] == 'separator':
                    wrapped_lines = textwrap.wrap(f"{entry['content']}", width=width-1)
                else:
                    wrapped_lines = textwrap.wrap(f"{entry['content']}", width=width-1)
                display_lines.extend(wrapped_lines)

            # Now display the last lines that fit on the screen
            max_display_lines = height - 2  # Reserve last line for instructions
            display_start = max(0, len(display_lines) - max_display_lines)
            for idx, line in enumerate(display_lines[display_start:]):
                try:
                    stdscr.addstr(idx, 0, line[:width-1])
                except curses.error:
                    pass  # Ignore if the string is too long for the window

            # Instructions at the bottom
            instruction = "Press 'M' for Menu | 'Q' to Quit."
            try:
                stdscr.addstr(height-1, 0, instruction[:width-1], curses.A_BOLD)
            except curses.error:
                pass  # Ignore if the string is too long for the window

            # Refresh the screen
            stdscr.refresh()

    except Exception as e:
        # In case of unexpected errors, display them before exiting
        stdscr.clear()
        h, w = stdscr.getmaxyx()
        error_message = f"An error occurred: {str(e)}"
        try:
            stdscr.addstr(h//2, w//2 - len(error_message)//2, error_message, curses.A_BOLD)
            stdscr.refresh()
            stdscr.getch()
        except curses.error:
            pass  # If even this fails, just exit
        logging.error(f"Unhandled exception: {e}")
    finally:
        # Signal threads to stop and wait for them to finish
        stop_event.set()
        speech_thread.join()
        if api_thread:
            api_thread.join()
        if tts_handler:
            tts_handler.stop()

def display_error(stdscr, message, tts_handler=None, config=None):
    """Display an error message in the curses interface and optionally speak it."""
    stdscr.clear()
    h, w = stdscr.getmaxyx()
    try:
        # Split message into lines if it's too long
        lines = message.split('\n')
        for idx, line in enumerate(lines):
            if idx >= h - 4:
                break  # Prevent writing beyond the window
            stdscr.addstr(h//2 - len(lines)//2 + idx, w//2 - len(line)//2, line[:w-1])
        stdscr.addstr(h//2 + 2, w//2 - 10, "Press any key to exit.")
        stdscr.refresh()
        stdscr.getch()
        # Speak the error message if TTS is enabled
        if tts_handler and config.get("tts_enabled", False):
            tts_handler.speak("An error occurred. Please check the logs for details.")
    except curses.error:
        pass  # If even this fails, just exit

# ======================= Entry Point ======================================
if __name__ == "__main__":
    if not is_venv():
        print("Setting up the virtual environment and installing dependencies. This may take a few minutes...")
        create_venv()
        install_dependencies()
        activate_venv()
        # Download Vosk model
        download_vosk_model()
        # Relaunch the script within the virtual environment
        if os.name == 'nt':
            python_executable = os.path.join(VENV_DIR, "Scripts", "python.exe")
        else:
            python_executable = os.path.join(VENV_DIR, "bin", "python")
        if not os.path.exists(python_executable):
            logging.error(f"Pip executable not found at {python_executable}")
            sys.exit("Error: Pip executable not found. Check the virtual environment setup.")
        logging.info("Relaunching the script within the virtual environment.")
        try:
            subprocess.check_call([python_executable] + sys.argv, stderr=SUBPROCESS_STDERR)
        except subprocess.CalledProcessError as e:
            logging.error(f"Failed to relaunch the script within the virtual environment: {e}")
            sys.exit("Error: Failed to relaunch the script within the virtual environment.")
        sys.exit()
    else:
        # If already in virtual environment, proceed to run the main function within curses
        curses.wrapper(main)
